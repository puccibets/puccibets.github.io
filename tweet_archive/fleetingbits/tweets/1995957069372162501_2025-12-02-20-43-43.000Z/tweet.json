{
  "id": "1995957069372162501",
  "url": "https://x.com/fleetingbits/status/1995957069372162501",
  "timestamp": "2025-12-02T20:43:43.000Z",
  "capturedAt": "2025-12-04T20:06:14.918Z",
  "author": "FleetingBits @fleetingbits",
  "authorName": "FleetingBits",
  "authorHandle": "@fleetingbits",
  "text": "Some thoughts on business strategy for Thinking Machines:\n\n1) I believe the two best directions for Thinking Machines are either to target an exit to a major technology company or to target the strategic deployment market.\n\n2) There are still a number of companies that would benefit from a $30bn-$60bn acquisition of Thinking. In particular, Apple, Amazon, and Microsoft would all benefit.\n\n3) If Thinking wants to go the exit direction, they should release an open source near-frontier model trained end-to-end in-house. This model should be equivalent to the top Chinese models.\n\n4) This would prove to potential acquirers that, with sufficient resources, they can build models competitive with OpenAI / Anthropic / DeepMind, which is the cornerstone of their valuation.\n\n5) They should also continue releasing open source research at the frontier. This generates community review of their work further builds credibility.\n\n6) They have a lot of famous researchers, but a single researcher can't build a top frontier model. Meta has shown you need something more. You have to show the team can deliver collectively.\n\n7) OpenAI and Google are fighting over the consumer market. Anthropic is fighting for the business API market and coding. It's very hard to break into either of these markets.\n\n8) Some of these require scaffolding and will soon require partnerships. There is also a data requirement. These markets are getting harder for someone new to enter.\n\n9) So the other desirable option is targeting the strategic deployment market, winning large value contracts to automate important enterprise workflows with respect to tasks that are not well addressed by general proprietary LLMs.\n\n10) These tend to be scientific applications (materials science, GPU/TPU design, drug discovery, advanced cybersecurity). \n\n11) Thinking can have more focus than the other foundation labs on these verticals and is a more desirable partner for enterprises than smaller startups like Periodic Labs or Prometheus Labs.\n\n12) These customers let you build up evaluations for these fields as you work with them, making it easier to build your next generation of models specialized for their needs. And, harder for competitors to acquire that data as well.\n\n13) There is a synergy here: model development for customers works well with Tinker since you are already making sure you tuning api is robust enough for various outside users, and staying in high-value scientific fields maintains your differentiation.\n\n14) Targeting the GPU/TPU design market is particularly desirable because all the foundation labs need to either commoditize that layer or otherwise bring it in-house. It's the major drag on their gross margins.\n\n15) It would be especially valuable to work with companies doing their own GPU/TPU development (AMD, Qualcomm). Thinking can develop experience automating this high-margin vertical. And, can do GPU / TPU deals with them as well.\n\n16) Meanwhile, Thinking should continue to productize the fine tuning API for researchers to the extent this is valuable. They iron out the kinks and give you insight into what research is being done, based on what researchers need from the API.\n\n17) Then, long-term, build out the API to be drop-and-drag ready for data scientists and ML teams in industry, both for general models and for building agents. This might mean offering a wider range of models beyond just LLMs.\n\n18) This ends up being the very low end of strategic deployment. FDEs can assist with customer adoption and then help pilot what data you want to purchase, this has been working well for Anthropic. Probably, part of what makes for \"Claudiness\".\n\n19) Some of these opportunities may require waiting for a research breakthrough  though before you can accomplish something meaningfully better than what frontier proprietary LLMs already offer. The perennial issue with fine-tuning.",
  "avatar": "fleetingbits/avatar/avatar.jpg",
  "avatarPath": "fleetingbits/avatar/avatar.jpg",
  "images": [],
  "jsonFile": "fleetingbits/tweets/1995957069372162501_2025-12-02-20-43-43.000Z/tweet.json",
  "mediaDir": "media",
  "userSlug": "fleetingbits"
}