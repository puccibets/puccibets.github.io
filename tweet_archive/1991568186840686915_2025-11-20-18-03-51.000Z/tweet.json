{
  "id": "1991568186840686915",
  "url": "https://x.com/SebastienBubeck/status/1991568186840686915/photo/1",
  "timestamp": "2025-11-20T18:03:51.000Z",
  "capturedAt": "2025-11-20T18:51:49.609Z",
  "author": "Noam Brown @polynoamial",
  "authorName": "Noam Brown",
  "authorHandle": "@polynoamial",
  "text": "The biggest misconception I hear about GenAI is that it inevitably outputs slop because it's trained to output \"the average of the internet\". But that's simply not true. It's trained to model the *entire distribution*, and RL lets it go beyond the human distribution.\n\nAlphaGo was a perfect demonstration of this. It learned the human distribution by training on a lot of Go games. Then, it used RL to go beyond the human distribution by discovering Move 37, a brilliant move that human experts initially thought was a blunder.\n\nAlphaGo was a narrow domain with an infinite curriculum and a perfect reward signal. The real world is a lot harder, and the jagged frontier of AI intelligence hasn't really surpassed top human capabilities yet.\n\nBut we're already starting to see LLMs contribute meaningfully to scientific research. As pretraining, RL, and test-time compute are scaled further, I expect we'll soon see a Move 37 for science.",
  "avatar": "media/1991568186840686915_avatar_8ywVGO5M_x96.jpg",
  "images": [
    "media/1991568186840686915_G6N4tlMacAUbPgQ"
  ],
  "jsonFile": "1991568186840686915_2025-11-20-18-03-51.000Z/tweet.json",
  "mediaDir": "media"
}